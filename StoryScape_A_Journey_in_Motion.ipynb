{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWGzxAKj7EKQ5oj9uecDen",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RashidNoor42/AI-Story-to-Video-Generator-using-Hugging-Face-Models/blob/main/StoryScape_A_Journey_in_Motion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffy2Jv19lXNd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "AI Video Generator - Creates videos from AI-generated stories\n",
        "\n",
        "INSTALLATION REQUIREMENTS:\n",
        "pip install torch transformers diffusers torchaudio moviepy pillow numpy gtts\n",
        "\n",
        "For better TTS (optional):\n",
        "- Ubuntu/Debian: sudo apt-get install espeak espeak-data\n",
        "- macOS: brew install espeak\n",
        "- Windows: Download from http://espeak.sourceforge.net/\n",
        "\n",
        "Then: pip install pyttsx3\n",
        "\"\"\"\n",
        "# Import necessary libraries\n",
        "from huggingface_hub import login\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import moviepy.editor as mpy\n",
        "import torchaudio\n",
        "from speechbrain.lobes.models.FastSpeech2 import FastSpeech2\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from speechbrain.lobes.models.FastSpeech2 import mel_spectogram\n",
        "from speechbrain.inference.vocoders import HIFIGAN\n",
        "import moviepy.editor as mpy\n",
        "\n",
        "import torchaudio\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import moviepy.editor as mpy\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# For TTS, we'll use multiple fallback options\n",
        "TTS_METHOD = None\n",
        "TTS_AVAILABLE = False\n",
        "# Step 1: Authenticate with Hugging Face\n",
        "login(token=\"HUGGING_FACE_TOKEN\")  # Using your Hugging Face token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Try gTTS first (more reliable)\n",
        "try:\n",
        "    from gtts import gTTS\n",
        "    TTS_METHOD = \"gtts\"\n",
        "    TTS_AVAILABLE = True\n",
        "    print(\"Using gTTS for text-to-speech\")\n",
        "except ImportError:\n",
        "    try:\n",
        "        import pyttsx3\n",
        "        TTS_METHOD = \"pyttsx3\"\n",
        "        TTS_AVAILABLE = True\n",
        "        print(\"Using pyttsx3 for text-to-speech\")\n",
        "    except ImportError:\n",
        "        print(\"Warning: No TTS library available. Install gtts or pyttsx3\")\n",
        "        TTS_AVAILABLE = False\n",
        "\n",
        "# Load GPT2 for text generation\n",
        "def load_gpt2():\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    # Set pad_token to eos_token to avoid warnings\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer, model\n",
        "\n",
        "def generate_text(prompt, tokenizer, model, max_length=200):\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    # Set attention mask\n",
        "    attention_mask = torch.ones(inputs.shape, dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=2,\n",
        "            do_sample=True,\n",
        "            temperature=0.8,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return text\n",
        "\n",
        "# Image Generation: Use Stable Diffusion\n",
        "def load_stable_diffusion():\n",
        "    try:\n",
        "        stable_diff_pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "        if torch.cuda.is_available():\n",
        "            stable_diff_pipe.to(\"cuda\")\n",
        "        return stable_diff_pipe\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Stable Diffusion: {e}\")\n",
        "        print(\"Using placeholder images instead\")\n",
        "        return None\n",
        "\n",
        "def generate_image_from_text(text_prompt, stable_diff_pipe):\n",
        "    if stable_diff_pipe is None:\n",
        "        # Create a placeholder image if Stable Diffusion is not available\n",
        "        img = Image.new('RGB', (512, 512), color=(np.random.randint(0, 255),\n",
        "                                                  np.random.randint(0, 255),\n",
        "                                                  np.random.randint(0, 255)))\n",
        "        return img\n",
        "\n",
        "    try:\n",
        "        image = stable_diff_pipe(text_prompt).images[0]\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating image: {e}\")\n",
        "        # Return placeholder image\n",
        "        img = Image.new('RGB', (512, 512), color=(128, 128, 128))\n",
        "        return img\n",
        "\n",
        "# TTS: Using multiple fallback approaches\n",
        "def generate_audio_from_text(text, filename=\"audio.wav\"):\n",
        "    if not TTS_AVAILABLE:\n",
        "        print(\"TTS not available. Creating silent video.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        if TTS_METHOD == \"gtts\":\n",
        "            # Using gTTS (Google Text-to-Speech) - more reliable\n",
        "            from gtts import gTTS\n",
        "            import io\n",
        "            # Truncate text if too long for gTTS\n",
        "            if len(text) > 1000:\n",
        "                text = text[:1000] + \"...\"\n",
        "            tts = gTTS(text=text, lang='en', slow=False)\n",
        "            tts.save(filename)\n",
        "\n",
        "        elif TTS_METHOD == \"pyttsx3\":\n",
        "            # Using pyttsx3 - requires eSpeak installation\n",
        "            import pyttsx3\n",
        "            engine = pyttsx3.init()\n",
        "            # Try to set properties to avoid errors\n",
        "            try:\n",
        "                engine.setProperty('rate', 150)    # Speed of speech\n",
        "                engine.setProperty('volume', 0.9)  # Volume level (0.0 to 1.0)\n",
        "            except:\n",
        "                pass\n",
        "            engine.save_to_file(text, filename)\n",
        "            engine.runAndWait()\n",
        "\n",
        "        # Verify file was created\n",
        "        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
        "            print(f\"Audio saved as {filename}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"Audio file was not created successfully\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio: {e}\")\n",
        "        print(\"Continuing without audio...\")\n",
        "        return False\n",
        "\n",
        "# Create a better story prompt\n",
        "def create_better_story(tokenizer, model):\n",
        "    story_prompt = \"Once upon a time, in a mystical kingdom, there lived a brave knight named Sir Arthur. One day, he embarked on a dangerous quest to\"\n",
        "    story = generate_text(story_prompt, tokenizer, model, max_length=300)\n",
        "\n",
        "    # Clean up the story by taking only the part that makes sense\n",
        "    sentences = story.split('.')\n",
        "    clean_sentences = []\n",
        "    for sentence in sentences[:8]:  # Take first 8 sentences\n",
        "        if len(sentence.strip()) > 10:  # Only include meaningful sentences\n",
        "            clean_sentences.append(sentence.strip())\n",
        "\n",
        "    return '. '.join(clean_sentences) + '.'\n",
        "\n",
        "# Create dynamic prompts based on the story\n",
        "def create_dynamic_prompts(story):\n",
        "    prompts = []\n",
        "    sentences = story.split('.')\n",
        "\n",
        "    # Create more descriptive prompts\n",
        "    base_prompts = [\n",
        "        \"A brave medieval knight in shining armor standing in a castle courtyard\",\n",
        "        \"A mystical fantasy kingdom with mountains and forests in the background\",\n",
        "        \"A knight on horseback riding through an enchanted forest\",\n",
        "        \"A dark cave entrance with mysterious glowing crystals\",\n",
        "        \"A knight facing a fierce dragon in an epic battle\",\n",
        "        \"A triumphant knight returning to his castle at sunset\"\n",
        "    ]\n",
        "\n",
        "    # If we have story sentences, try to incorporate them\n",
        "    for i, sentence in enumerate(sentences[:6]):\n",
        "        if len(sentence.strip()) > 5:\n",
        "            prompt = f\"Fantasy art style: {sentence.strip()}, medieval setting, cinematic lighting\"\n",
        "            prompts.append(prompt)\n",
        "        elif i < len(base_prompts):\n",
        "            prompts.append(base_prompts[i])\n",
        "\n",
        "    # Fill remaining slots with base prompts if needed\n",
        "    while len(prompts) < 6:\n",
        "        prompts.append(base_prompts[len(prompts)])\n",
        "\n",
        "    return prompts[:6]  # Return exactly 6 prompts\n",
        "\n",
        "# Create video from images and audio\n",
        "def create_video(images, audio_filename, output_filename=\"output_video.mp4\"):\n",
        "    try:\n",
        "        clips = []\n",
        "\n",
        "        # Save images temporarily and create clips\n",
        "        temp_image_files = []\n",
        "        for i, img in enumerate(images):\n",
        "            temp_filename = f\"temp_img_{i}.png\"\n",
        "            img.save(temp_filename)\n",
        "            temp_image_files.append(temp_filename)\n",
        "\n",
        "            img_clip = mpy.ImageClip(temp_filename)\n",
        "            img_clip = img_clip.set_duration(5)  # Each image for 5 seconds\n",
        "            clips.append(img_clip)\n",
        "\n",
        "        # Concatenate all image clips\n",
        "        print(\"Creating video sequence...\")\n",
        "        video = mpy.concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "        # Add audio if available\n",
        "        if audio_filename and os.path.exists(audio_filename) and os.path.getsize(audio_filename) > 0:\n",
        "            try:\n",
        "                print(\"Adding audio to video...\")\n",
        "                audio = mpy.AudioFileClip(audio_filename)\n",
        "                # Match video length to audio or vice versa\n",
        "                video_duration = min(30, video.duration)\n",
        "                if audio.duration > video_duration:\n",
        "                    audio = audio.subclip(0, video_duration)\n",
        "                elif video.duration > audio.duration:\n",
        "                    video = video.subclip(0, audio.duration)\n",
        "                video = video.set_audio(audio)\n",
        "                print(\"Audio added successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error adding audio: {e}\")\n",
        "                print(\"Creating video without audio...\")\n",
        "        else:\n",
        "            print(\"No audio file available, creating silent video...\")\n",
        "\n",
        "        # Ensure video doesn't exceed 30 seconds\n",
        "        if video.duration > 30:\n",
        "            video = video.subclip(0, 30)\n",
        "\n",
        "        # Write video file with more error handling\n",
        "        print(f\"Writing video file: {output_filename}\")\n",
        "        video.write_videofile(\n",
        "            output_filename,\n",
        "            fps=24,\n",
        "            verbose=False,\n",
        "            logger=None,\n",
        "            audio_codec='aac' if video.audio else None\n",
        "        )\n",
        "\n",
        "        # Clean up temporary files\n",
        "        for temp_file in temp_image_files:\n",
        "            try:\n",
        "                if os.path.exists(temp_file):\n",
        "                    os.remove(temp_file)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(f\"Video created successfully: {output_filename}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating video: {e}\")\n",
        "        # Try to clean up temp files even if video creation failed\n",
        "        try:\n",
        "            for temp_file in temp_image_files:\n",
        "                if os.path.exists(temp_file):\n",
        "                    os.remove(temp_file)\n",
        "        except:\n",
        "            pass\n",
        "        return False\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    print(\"Loading models...\")\n",
        "\n",
        "    # Load GPT-2 for text generation\n",
        "    tokenizer, model = load_gpt2()\n",
        "\n",
        "    # Generate story\n",
        "    print(\"Generating story...\")\n",
        "    story = create_better_story(tokenizer, model)\n",
        "    print(\"Generated Story:\")\n",
        "    print(story)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Create dynamic prompts\n",
        "    prompts = create_dynamic_prompts(story)\n",
        "    print(\"Generated Prompts for Image Generation:\")\n",
        "    for i, prompt in enumerate(prompts, 1):\n",
        "        print(f\"{i}. {prompt}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Load Stable Diffusion\n",
        "    print(\"Loading Stable Diffusion...\")\n",
        "    stable_diff_pipe = load_stable_diffusion()\n",
        "\n",
        "    # Generate images\n",
        "    print(\"Generating images...\")\n",
        "    images = []\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        print(f\"Generating image {i+1}/6...\")\n",
        "        image = generate_image_from_text(prompt, stable_diff_pipe)\n",
        "        images.append(image)\n",
        "\n",
        "    # Generate audio\n",
        "    print(\"Generating audio...\")\n",
        "    audio_filename = \"story_audio.wav\"\n",
        "    audio_success = generate_audio_from_text(story, audio_filename)\n",
        "\n",
        "    # Create video (with or without audio)\n",
        "    print(\"Creating video...\")\n",
        "    video_success = create_video(images, audio_filename if audio_success else None)\n",
        "\n",
        "    if video_success:\n",
        "        print(\"Process completed successfully!\")\n",
        "    else:\n",
        "        print(\"Process completed with errors. Check the output above.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "b0uf8_btm64f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # This should return True if GPU is available\n"
      ],
      "metadata": {
        "id": "L4Ops-UAsJvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install speechbrain\n",
        "\n",
        "# pip install transformers torch\n",
        "\n",
        "# pip install speechbrain transformers torchaudio moviepy diffusers\n",
        "\n",
        "# pip install diffusers torch\n",
        "\n",
        "# pip install torch transformers diffusers torchaudio moviepy pillow numpy\n",
        "\n",
        "\n",
        "# pip install gtts     # Google TTS (requires internet)\n",
        "\n",
        "# pip install pyttsx3"
      ],
      "metadata": {
        "id": "wsEtKIEIWiPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hE-jSv8ZWpNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}